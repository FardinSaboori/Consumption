{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ea913e-2bd9-455f-a86c-5ba5bc92b87e",
   "metadata": {},
   "source": [
    "In this notebook we will predict the energy consumption(KWH) based on the other available features in our dataset which is located here:\n",
    "\n",
    "https://www.eia.gov/consumption/residential/data/2009/index.php?view=mic\n",
    "\n",
    "Since we are trying to predict a continous variable(KWH) we will need to use a regression based model that can handle a huge dataset with many features and avoid overfitting and provide us with some hyperparamers to tune the model. In this case, i have decided to use XGBregressor as it provides several parameters such as lambda and gamma to avoid overfitting and underfitting and also adjust the effect of significant values.\n",
    "\n",
    "Let's import some packages and read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743b233-2fb6-401a-a0ad-156e620c6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c5397be5-c13f-46e8-9b58-fccbca220cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('recs2009_public.csv', parse_dates= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "43c8e87d-c93d-468e-9ac9-3100a74bc6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOEID</th>\n",
       "      <th>REGIONC</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REPORTABLE_DOMAIN</th>\n",
       "      <th>TYPEHUQ</th>\n",
       "      <th>NWEIGHT</th>\n",
       "      <th>HDD65</th>\n",
       "      <th>CDD65</th>\n",
       "      <th>HDD30YR</th>\n",
       "      <th>CDD30YR</th>\n",
       "      <th>...</th>\n",
       "      <th>SCALEKER</th>\n",
       "      <th>IECC_Climate_Pub</th>\n",
       "      <th>HDD50</th>\n",
       "      <th>CDD80</th>\n",
       "      <th>GND_HDD65</th>\n",
       "      <th>WSF</th>\n",
       "      <th>OA_LAT</th>\n",
       "      <th>GWT</th>\n",
       "      <th>DesignDBT99</th>\n",
       "      <th>DesignDBT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2471.68</td>\n",
       "      <td>4742</td>\n",
       "      <td>1080</td>\n",
       "      <td>4953</td>\n",
       "      <td>1271</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>4A</td>\n",
       "      <td>2117</td>\n",
       "      <td>56</td>\n",
       "      <td>4250</td>\n",
       "      <td>0.48</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>8599.17</td>\n",
       "      <td>2662</td>\n",
       "      <td>199</td>\n",
       "      <td>2688</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>3C</td>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "      <td>2393</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8969.92</td>\n",
       "      <td>6233</td>\n",
       "      <td>505</td>\n",
       "      <td>5741</td>\n",
       "      <td>829</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>5A</td>\n",
       "      <td>2346</td>\n",
       "      <td>49</td>\n",
       "      <td>5654</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>18003.64</td>\n",
       "      <td>6034</td>\n",
       "      <td>672</td>\n",
       "      <td>5781</td>\n",
       "      <td>868</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>5A</td>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>4941</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5999.61</td>\n",
       "      <td>5388</td>\n",
       "      <td>702</td>\n",
       "      <td>5313</td>\n",
       "      <td>797</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>5A</td>\n",
       "      <td>2251</td>\n",
       "      <td>0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12078</th>\n",
       "      <td>12079</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10219.80</td>\n",
       "      <td>7671</td>\n",
       "      <td>332</td>\n",
       "      <td>7784</td>\n",
       "      <td>451</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>6A-6B</td>\n",
       "      <td>4289</td>\n",
       "      <td>39</td>\n",
       "      <td>7819</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>-3</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>12080</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>8689.07</td>\n",
       "      <td>2085</td>\n",
       "      <td>2844</td>\n",
       "      <td>2520</td>\n",
       "      <td>2286</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>3B-4B</td>\n",
       "      <td>360</td>\n",
       "      <td>393</td>\n",
       "      <td>1869</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12080</th>\n",
       "      <td>12081</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4697.21</td>\n",
       "      <td>7935</td>\n",
       "      <td>472</td>\n",
       "      <td>8074</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>6A-6B</td>\n",
       "      <td>4494</td>\n",
       "      <td>22</td>\n",
       "      <td>8477</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>-9</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12081</th>\n",
       "      <td>12082</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>13155.68</td>\n",
       "      <td>5834</td>\n",
       "      <td>770</td>\n",
       "      <td>5989</td>\n",
       "      <td>957</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>5B-5C</td>\n",
       "      <td>2840</td>\n",
       "      <td>0</td>\n",
       "      <td>9010</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>12083</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>7703.43</td>\n",
       "      <td>2806</td>\n",
       "      <td>124</td>\n",
       "      <td>2859</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>3C</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>3048</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12083 rows × 940 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DOEID  REGIONC  DIVISION  REPORTABLE_DOMAIN  TYPEHUQ   NWEIGHT  HDD65  \\\n",
       "0          1        2         4                 12        2   2471.68   4742   \n",
       "1          2        4        10                 26        2   8599.17   2662   \n",
       "2          3        1         1                  1        5   8969.92   6233   \n",
       "3          4        2         3                  7        2  18003.64   6034   \n",
       "4          5        1         1                  1        3   5999.61   5388   \n",
       "...      ...      ...       ...                ...      ...       ...    ...   \n",
       "12078  12079        2         3                  9        2  10219.80   7671   \n",
       "12079  12080        3         7                 21        4   8689.07   2085   \n",
       "12080  12081        2         4                 10        2   4697.21   7935   \n",
       "12081  12082        4         8                 23        2  13155.68   5834   \n",
       "12082  12083        4        10                 26        2   7703.43   2806   \n",
       "\n",
       "       CDD65  HDD30YR  CDD30YR  ...  SCALEKER  IECC_Climate_Pub HDD50 CDD80  \\\n",
       "0       1080     4953     1271  ...        -2                4A  2117    56   \n",
       "1        199     2688      143  ...        -2                3C    62    26   \n",
       "2        505     5741      829  ...        -2                5A  2346    49   \n",
       "3        672     5781      868  ...        -2                5A  2746     0   \n",
       "4        702     5313      797  ...        -2                5A  2251     0   \n",
       "...      ...      ...      ...  ...       ...               ...   ...   ...   \n",
       "12078    332     7784      451  ...        -2             6A-6B  4289    39   \n",
       "12079   2844     2520     2286  ...        -2             3B-4B   360   393   \n",
       "12080    472     8074      600  ...        -2             6A-6B  4494    22   \n",
       "12081    770     5989      957  ...        -2             5B-5C  2840     0   \n",
       "12082    124     2859      139  ...        -2                3C    92     0   \n",
       "\n",
       "       GND_HDD65   WSF  OA_LAT  GWT  DesignDBT99  DesignDBT1  \n",
       "0           4250  0.48       6   56            9          96  \n",
       "1           2393  0.61       0   64           38          73  \n",
       "2           5654  0.48       3   52           12          88  \n",
       "3           4941  0.55       4   55            7          87  \n",
       "4           5426  0.61       4   50           13          90  \n",
       "...          ...   ...     ...  ...          ...         ...  \n",
       "12078       7819  0.59       0   48           -3          84  \n",
       "12079       1869  0.50       0   56           26         101  \n",
       "12080       8477  0.58       1   46           -9          89  \n",
       "12081       9010  0.54       1   53           13          93  \n",
       "12082       3048  0.53       0   60           44          75  \n",
       "\n",
       "[12083 rows x 940 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "21ccf769-8f5e-47e7-b5ea-6f78a645e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbeda3-babd-4bf0-8e21-c7cf6dd811b5",
   "metadata": {},
   "source": [
    "There is no Null values in our dataset! However we need to handle the categorical variables and make some dummies out of them. on some columns we have both string and numeric elemnts we need to change them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f9c6257c-d713-4bea-b087-efc666caa18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      885\n",
       "float64     50\n",
       "object       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ec75e365-35e8-45c5-8ca6-5f23b302f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [col for col in data.columns if data[col].dtype ==\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "15a83380-e8e2-43aa-89ae-3ace4089957e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METROMICRO', 'UR', 'NOCRCASH', 'NKRGALNC', 'IECC_Climate_Pub']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b7dbf987-a5d2-4076-bffc-8373936d7b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, 1, 6, 15, 4, '-2', '1', '20', '.', '12', '4', '10', '3', '24',\n",
       "       '55', '6', 8, 28, 5, 55, 3, 16, 2, 20, 10, 24, 40, 12, 25],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['NOCRCASH'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "33135b06-e904-46df-b931-814807951a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4A', '3C', '5A', '6A-6B', '1A-2A', '3B-4B', '3A', '5B-5C',\n",
       "       '7A-7B-7AK-8AK', '2B', '4C'], dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['IECC_Climate_Pub'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bd83455d-2b8d-4c1f-a31e-36a9feee549e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, 1, 5, 10, '-2', '10', '15', '1', '8', '.', '5', '3', '2', '77',\n",
       "       30, 3, 15, 8, 55, 2, 20], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['NKRGALNC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "be5e0dc6-a639-42b4-be0b-6be0c9350f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['NKRGALNC'] != '.') | (data['NOCRCASH'] != '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "db53d289-a378-419f-9db8-122a7bb26f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NOCRCASH']= pd.to_numeric(data['NOCRCASH'])\n",
    "data['NKRGALNC']= pd.to_numeric(data['NKRGALNC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "90fa2438-7420-4982-9e14-dc128617dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [col for col in data.columns if data[col].dtype ==\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d8e6f4ee-3aa2-42b3-9e16-78e60eecde65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METROMICRO', 'UR', 'IECC_Climate_Pub']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d7937f0b-ab47-4d62-94b8-3826fdeda7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(cat_col, data):\n",
    "    for col in cat_col:\n",
    "        dummied = pd.get_dummies(data[col])\n",
    "        data = pd.concat([data.drop(col, axis = 1), dummied] ,axis = 1)\n",
    "    return data\n",
    "data = cat_to_num(cat_col,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ad91c5e0-098b-495a-a996-a64ff40635ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      887\n",
       "float64     50\n",
       "uint8       16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a61ea-e6c9-42f6-b73f-a3907ae77d92",
   "metadata": {},
   "source": [
    "## Let's examine the distribution of our target variable to spot the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8b5e60e5-e7e4-45da-a9a6-edf6472dd948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='KWH'>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data['KWH'].plot()\n",
    "import math\n",
    "sns.boxplot(data=data,  x='KWH', palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717660b-c1d7-46c2-b0a8-41873780ca37",
   "metadata": {},
   "source": [
    "## Looking at 25th and 75th percentiles we see that most of our data lays between 5.8k and 14.7k and we can easily observe many outliers if we calculate the IQR *1.5 + 75th percentile so here i have decided to remove anything greater than 40000 to not lose to much info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "892cfd63-ec48-45cc-b17c-a5976ce8a36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     12081.000000\n",
       "mean      11289.533068\n",
       "std        7641.077130\n",
       "min          17.000000\n",
       "25%        5841.000000\n",
       "50%        9623.000000\n",
       "75%       14768.000000\n",
       "max      150254.000000\n",
       "Name: KWH, dtype: object"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['KWH'].describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ead2ae9c-a5fa-4613-900e-9d7351b8c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['KWH'] <40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "052a4e27-65c2-4645-84ec-6e264fe2efbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MICRO          2\n",
       "GARGLOC        1\n",
       "ZTEMPNITEAC    1\n",
       "FUELPOOL       1\n",
       "3C             1\n",
       "              ..\n",
       "ZTYPECLN       1\n",
       "ZUSENGFP       1\n",
       "HELPCW         1\n",
       "CHRGPLGE       1\n",
       "OUTLET         1\n",
       "Length: 952, dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5ef73000-8bd5-4ba2-8ebc-9288fb7fa3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MICRO1'] = data['MICRO'].iloc[:,0]\n",
    "data.drop('MICRO', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de170006-061c-459f-b8bd-276dd4afda0d",
   "metadata": {},
   "source": [
    "## We are going to use a special method called wrapper to select usefull features out of our huge dataset, so we first train the XGB with the whole dataset to capture the feature importances(gain from each feature) and then using the built in class of \"SelectFromModel\" in XGB with a certaing threshhold we pick the right features that our model gain the most info from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "05be0572-13f9-457e-a549-a33497bb6534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.994122385979, n=1, MAE: 13.75\n",
      "Thresh=0.000494635780, n=2, MAE: 14.09\n",
      "Thresh=0.000294105004, n=3, MAE: 14.27\n",
      "Thresh=0.000190245031, n=4, MAE: 14.64\n",
      "Thresh=0.000156704002, n=5, MAE: 14.46\n",
      "Thresh=0.000115859679, n=6, MAE: 14.59\n",
      "Thresh=0.000097834134, n=7, MAE: 15.48\n",
      "Thresh=0.000096075943, n=8, MAE: 15.73\n",
      "Thresh=0.000076290424, n=9, MAE: 14.92\n",
      "Thresh=0.000059029157, n=10, MAE: 15.36\n",
      "Thresh=0.000054499043, n=11, MAE: 15.01\n",
      "Thresh=0.000053412732, n=12, MAE: 15.69\n",
      "Thresh=0.000053268530, n=13, MAE: 15.62\n",
      "Thresh=0.000049350576, n=14, MAE: 15.73\n",
      "Thresh=0.000046925004, n=15, MAE: 15.79\n",
      "Thresh=0.000046882080, n=16, MAE: 15.79\n",
      "Thresh=0.000046355381, n=17, MAE: 16.34\n",
      "Thresh=0.000044920096, n=18, MAE: 16.87\n",
      "Thresh=0.000044551562, n=19, MAE: 16.52\n",
      "Thresh=0.000043389362, n=20, MAE: 16.73\n",
      "Thresh=0.000041283041, n=21, MAE: 17.06\n",
      "Thresh=0.000040268227, n=22, MAE: 18.04\n",
      "Thresh=0.000039258419, n=23, MAE: 18.39\n",
      "Thresh=0.000037624821, n=24, MAE: 18.46\n",
      "Thresh=0.000037391455, n=25, MAE: 17.87\n",
      "Thresh=0.000036303034, n=26, MAE: 17.54\n",
      "Thresh=0.000034729048, n=27, MAE: 18.71\n",
      "Thresh=0.000034402248, n=28, MAE: 18.26\n",
      "Thresh=0.000034378525, n=29, MAE: 17.85\n",
      "Thresh=0.0000137054, n=100, MAE: 29.34\n",
      "Thresh=0.0000080201, n=200, MAE: 30.84\n",
      "Thresh=0.0000050509, n=300, MAE: 31.54\n",
      "Thresh=0.0000022973, n=400, MAE: 33.60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data.drop(['KWH', 'DOEID'], axis = 1)\n",
    "# X = data[['DIVISION', 'REGIONC','TYPEHUQ','NWEIGHT','HDD30YR']]\n",
    "Y = data['KWH']\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = metrics.mean_absolute_error(y_test, predictions)\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sorted(model.feature_importances_, reverse=True)\n",
    "for thresh in thresholds:\n",
    "    if thresh > 0:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        # train model\n",
    "        selection_model = XGBRegressor()\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = metrics.mean_absolute_error(y_test, predictions)\n",
    "        if select_X_train.shape[1] < 30:\n",
    "            print(\"Thresh=%.12f, n=%d, MAE: %.2f\" % (thresh, select_X_train.shape[1], accuracy))\n",
    "        elif select_X_train.shape[1] % 100 == 0:\n",
    "            print(\"Thresh=%.10f, n=%d, MAE: %.2f\" % (thresh, select_X_train.shape[1], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091625c5-f9d2-4669-a594-3d533ae042c8",
   "metadata": {},
   "source": [
    "## So here as seen, from n=1 to n=6 we are obsering a very low MAE and the gap between these MAEs are very small so here i have made a trade-off by choosing the n=6 which has a lower MAE compared to n=1 to generalize our model for the future and unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "42be6f28-febf-4a7a-916d-dce7dfdb93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = model.get_booster().get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "feat_imp_df = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "768e5592-4630-4d8a-ae68-4d41307d4db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feat_imp_df['score']>20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6c843bae-40d2-4a8a-bc1c-5e9abab6637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BTUEL</th>\n",
       "      <td>9.330328e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HELPWS</th>\n",
       "      <td>4.642400e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HELPCWY</th>\n",
       "      <td>2.760320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFRIG3</th>\n",
       "      <td>1.785543e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KAVALEL</th>\n",
       "      <td>1.470744e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASEHEAT</th>\n",
       "      <td>3.685981e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREEZER</th>\n",
       "      <td>3.538369e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUELFOOD</th>\n",
       "      <td>2.445312e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOVE</th>\n",
       "      <td>3.221445e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROTHERM</th>\n",
       "      <td>1.858008e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 score\n",
       "BTUEL     9.330328e+08\n",
       "HELPWS    4.642400e+05\n",
       "HELPCWY   2.760320e+05\n",
       "ESFRIG3   1.785543e+05\n",
       "KAVALEL   1.470744e+05\n",
       "...                ...\n",
       "BASEHEAT  3.685981e+02\n",
       "FREEZER   3.538369e+02\n",
       "FUELFOOD  2.445312e+02\n",
       "STOVE     3.221445e+01\n",
       "PROTHERM  1.858008e+01\n",
       "\n",
       "[439 rows x 1 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6895ae-f591-4014-8519-199429058980",
   "metadata": {},
   "source": [
    "## Now let's train our model using the selected features that we found from the previous step and apply a cross validation method to fidn the right parameters of our model to further improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "768884c9-3f8b-4a2c-9cdd-6afb759f7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "data_dmatrix = xgb.DMatrix(data=select_X_train,label=y_train)\n",
    "grid = pd.DataFrame({'eta':[0.299,0.3001,0.301,0.3]*2,\n",
    "'subsample':np.repeat([0.95,1],4)})\n",
    "def fit(x):\n",
    "    params = {'objective':'reg:squarederror',\n",
    "              'eval_metric':'logloss',\n",
    "              'eta':x[0],\n",
    "              'subsample':x[1]}\n",
    "    xgb_cv = xgb.cv(dtrain=data_dmatrix, params=params, \n",
    "    nfold=5, metrics = 'logloss',seed=42)\n",
    "    return xgb_cv[-1:].values[0]\n",
    "\n",
    "grid[['train-logloss-mean','train-logloss-std',\n",
    "'test-logloss-mean','test-logloss-std']] = grid.apply(fit,axis=1,result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6d4abff1-07ed-4944-9bdb-431b4b9432e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>subsample</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-408588.26875</td>\n",
       "      <td>1096.962919</td>\n",
       "      <td>-408587.93750</td>\n",
       "      <td>4386.879811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-408588.23750</td>\n",
       "      <td>1096.918619</td>\n",
       "      <td>-408587.88750</td>\n",
       "      <td>4386.886565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-408588.26875</td>\n",
       "      <td>1096.972538</td>\n",
       "      <td>-408587.95625</td>\n",
       "      <td>4386.902120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-408588.30000</td>\n",
       "      <td>1096.901749</td>\n",
       "      <td>-408587.93125</td>\n",
       "      <td>4386.867289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2990</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-408588.28125</td>\n",
       "      <td>1096.960377</td>\n",
       "      <td>-408587.96875</td>\n",
       "      <td>4386.922022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-408588.24375</td>\n",
       "      <td>1096.979952</td>\n",
       "      <td>-408587.93125</td>\n",
       "      <td>4386.929634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-408588.20000</td>\n",
       "      <td>1096.954316</td>\n",
       "      <td>-408587.92500</td>\n",
       "      <td>4386.912440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-408588.23125</td>\n",
       "      <td>1096.964927</td>\n",
       "      <td>-408587.91875</td>\n",
       "      <td>4386.917720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eta  subsample  train-logloss-mean  train-logloss-std  \\\n",
       "0  0.2990       0.95       -408588.26875        1096.962919   \n",
       "1  0.3001       0.95       -408588.23750        1096.918619   \n",
       "2  0.3010       0.95       -408588.26875        1096.972538   \n",
       "3  0.3000       0.95       -408588.30000        1096.901749   \n",
       "4  0.2990       1.00       -408588.28125        1096.960377   \n",
       "5  0.3001       1.00       -408588.24375        1096.979952   \n",
       "6  0.3010       1.00       -408588.20000        1096.954316   \n",
       "7  0.3000       1.00       -408588.23125        1096.964927   \n",
       "\n",
       "   test-logloss-mean  test-logloss-std  \n",
       "0      -408587.93750       4386.879811  \n",
       "1      -408587.88750       4386.886565  \n",
       "2      -408587.95625       4386.902120  \n",
       "3      -408587.93125       4386.867289  \n",
       "4      -408587.96875       4386.922022  \n",
       "5      -408587.93125       4386.929634  \n",
       "6      -408587.92500       4386.912440  \n",
       "7      -408587.91875       4386.917720  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da85da-f92c-4f38-891d-062d4514d544",
   "metadata": {},
   "source": [
    "As we can see, row 5 has the best scores so we will retrain our model using those parameteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "db93e25e-7682-4544-bc73-b2c345603dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eta=0.3001, eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300099999, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=96, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                           eval_metric = 'logloss',\n",
    "                           eta = 0.3001,\n",
    "                           subsample = 1)\n",
    "\n",
    "xgb_reg.fit(select_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a1ad371b-91c5-4f6c-b41a-8655cb0aa040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=6, Accuracy: 14.24\n"
     ]
    }
   ],
   "source": [
    "select_X_test = selection.transform(X_test)\n",
    "y_pred = xgb_reg.predict(select_X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = metrics.mean_absolute_error(y_test, predictions)\n",
    "print(\"Thresh=%.3f, n=%d, Accuracy: %.2f\" % (thresh, select_X_train.shape[1], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85d285-3ea5-4f4b-8cde-83497e4b3994",
   "metadata": {},
   "source": [
    "# Great! we were abale to both select the best features and also we were able to improve the MAE further!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
